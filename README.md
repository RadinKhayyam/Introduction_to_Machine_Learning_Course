# ü§ñ Introduction to Machine Learning

**üèõÔ∏è University:** Sharif University of Technology  
**üè¢ Department:** Electrical Engineering  
**üë®‚Äçüè´ Instructor:** Prof. Mohammad Bagher Shamsollahi  

---

## üìò Course Overview

This course introduces the foundational concepts and techniques in machine learning, providing students with the theoretical and practical tools to solve classification, regression, and clustering problems. The course covers both linear and non-linear models, supervised and unsupervised learning, feature engineering, and model evaluation techniques. Through hands-on projects and theoretical analysis, students will develop the skills needed to apply machine learning algorithms to real-world data.

**Textbooks:**
- S. Theodoridis and K. Koutroumbas, *Pattern Recognition* (Fourth Edition), Academic Press, 2009.  
- K. P. Murphy, *Probabilistic Machine Learning: An Introduction*, MIT Press, 2022.

---

## üìù Syllabus

### 1Ô∏è‚É£ **Introduction to Machine Learning Concepts and Mathematical Foundations**  
- Introduction to machine learning and its applications  
- Review of relevant mathematical concepts: probability theory, linear algebra, and optimization  
- Types of learning: supervised, unsupervised, semi-supervised, and reinforcement learning  
- Overview of classification, regression, and clustering tasks  

### 2Ô∏è‚É£ **Bayesian Decision Theory for Classification**  
- Bayesian statistical classifiers  
- Minimizing risk and decision boundaries  
- Bayesian classifier with Gaussian distribution assumptions  
- Parametric and non-parametric probability density estimation  
- Non-linear classifiers: k-Nearest Neighbors (kNN) and Probabilistic Neural Networks (PNN)  

### 3Ô∏è‚É£ **Evaluating Learning Algorithms**  
- Evaluation metrics for classification: accuracy, precision, recall, F1-score  
- Handling balanced and imbalanced datasets  
- Performance evaluation for regression models  
- Cross-validation techniques  

### 4Ô∏è‚É£ **Linear Classifiers**  
- Introduction to discriminant functions  
- Designing linear classifiers for linearly separable data  
  - Perceptron algorithm  
  - Variants of the perceptron algorithm  
- Designing linear classifiers for non-linearly separable data  
  - Algebraic and statistical approaches  
- Introduction to regression  
  - Logistic regression  
- Support Vector Machines (SVM):  
  - Linearly separable and non-linearly separable cases  
- Extension of binary classifiers to multi-class problems  

### 5Ô∏è‚É£ **Non-Linear Classifiers and Neural Networks**  
- Introduction to multi-layer perceptrons (MLP)  
  - Single-layer, two-layer, and multi-layer perceptrons  
- Artificial Neural Networks (ANN) and model fitting  
- Neural networks and deep learning  
- Generalized linear classifiers  
- Radial Basis Function Networks (RBFNN)  
- Probabilistic Neural Networks (PNN)  
- Non-linear SVM classifiers  
- Decision Trees  

### 6Ô∏è‚É£ **Ensemble Learning**  
- Combining classifiers for better performance  
  - Feature/data splitting (Bagging)  
  - Hard majority voting  
  - Soft voting based on posterior probabilities  
- Bayesian approaches for combining classifiers  
- Kullback-Leibler divergence and posterior probability  
- Geometric and arithmetic mean rules  
- Boosting methods: Adaboost and beyond  
- Dealing with imbalanced data in ensemble methods  

### 7Ô∏è‚É£ **Feature Engineering**  
- Introduction to feature engineering and preprocessing  
- Normalization and standardization of features  
- The relationship between feature dimensionality and training data size  
- Feature reduction techniques  
  - Feature selection criteria  
  - Search methods for feature selection  
- Dimensionality reduction:  
  - Linear methods (PCA, LDA)  
  - Non-linear methods (t-SNE, UMAP)  

### 8Ô∏è‚É£ **Clustering**  
- Introduction to clustering and its applications  
- Steps in clustering analysis  
- Different clustering approaches: hierarchical, partitioning, density-based, and model-based  
- Cluster representation and evaluation  
- Proximity measures (similarity/dissimilarity)  
  - Between two vectors  
  - Between a vector and a cluster  
  - Between two clusters  
- Calculating possible cluster formations  
- Sequential and cost-function-based clustering algorithms  
- Evaluating clustering performance  

---

## üéØ Prerequisites  
- Basic understanding of probability theory and statistics  
- Knowledge of linear algebra  
- Familiarity with Python programming  

## üìä Grade Distribution  
- **20%** First mid-term
- **25%** Second mid-term
- **25%** Final Exam
- **10%** Theoretical Assignments  
- **10%** Computer Assignments
- **10%** Final Project
